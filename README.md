# Домашнее задание 4: Логистическая регрессия

## Постановка задачи

В этом задании предстоит разработать модель машинного обучения для диагностики диабета на основе медицинских показателей пациентов

Мы будем использовать классический датасет **Pima Indians Diabetes**

Ваша задача - не просто обучить модель (`model.fit`), а построить **полноценный пайплайн**, который включает:

1.  Грамотную предобработку данных (чистка, заполнение пропусков, масштабирование).
2.  Обучение Логистической регрессии.
3.  Комплексную оценку качества с использованием метрик классификации.

## Структура проекта

```text
ml-logreg-hw/
├── pyproject.toml       # Конфигурация зависимостей (uv)
├── README.md            # Этот файл
├── src/
│   ├── __init__.py
│   └── model.py         # код здеся
└── tests/
    ├── __init__.py
    └── test_model.py    # Автоматические тесты
```

## Как начать

Мы используем менеджер пакетов `uv`.

1. Инициализация:


```bash
uv sync
```

2. Запуск тестов:


```bash
uv run pytest -v
```

Сразу после скачивания тесты будут падать. Ваша задача - сделать их зелеными.

---

## Задание

Необходимо реализовать методы класса `DiabetesClassifier` в файле `src/model.py`.

### Этап 1: Предобработка данных (`preprocess_data`)

Данные содержат "скрытые" пропуски. Например, у человека не может быть `Glucose = 0` или `BloodPressure = 0`. В этом датасете нули используются как заглушка для отсутствующих данных.

#### Что нужно сделать:
1.  В колонках `['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']` заменить значения `0` на `NaN`.
2.  Разделить данные на матрицу признаков $X$ и вектор ответов $y$ (колонка `Outcome`).
3.  **Заполнение пропусков (Imputation):** Используйте `SimpleImputer` (медиана), чтобы заполнить `NaN`.
4.  **Масштабирование (Scaling):** Используйте `StandardScaler`, чтобы привести признаки к нормальному виду (среднее 0, дисперсия 1). 

> Это критически важно для Логистической регрессии

#### Важно про Data Leakage:
Метод принимает флаг `is_training`.
*   Если `is_training=True`: Вы должны **обучить** (`fit`) импьютер и скейлер на данных, а потом применить их (`transform`).
*   Если `is_training=False`: Вы должны **только применить** (`transform`) уже обученные инструменты. 

> Нельзя пересчитывать среднее на тестовой выборке

### Этап 2: Обучение (`train`)

1.  Вызвать `preprocess_data` с флагом `is_training=True`.
2.  Обучить модель `self.model` (это `LogisticRegression` из sklearn) на полученных данных.

### Этап 3: Предсказание (`predict` и `predict_proba`)

1.  Вызвать `preprocess_data` с флагом `is_training=False`.
2.  `predict`: Вернуть классы (0 или 1).
3.  `predict_proba`: Вернуть вероятность класса 1 (вам нужна вторая колонка результата метода sklearn).

### Этап 4: Оценка (`evaluate`)

Метод должен возвращать словарь с ключевыми метриками:
*   `Accuracy` (Доля правильных ответов)
*   `Precision` (Точность)
*   `Recall` (Полнота)
*   `F1 Score` (Гармоническое среднее)
*   `ROC-AUC` (Площадь под ROC-кривой)


---

## Подсказки

1.  **Pandas:** Для замены нулей удобно использовать `df[cols] = df[cols].replace(0, np.nan)`.
2.  **Sklearn:**
    *   `scaler.fit_transform(X)` - для трейна.
    *   `scaler.transform(X)` - для теста.
3.  **Логистическая регрессия:** Убедитесь, что вы возвращаете `predict_proba` именно для класса 1 (положительного класса), а не матрицу для обоих классов.

## Критерии успеха

1.  Все тесты (`pytest`) проходят успешно.
2.  В коде нет Data Leakage (скалер не обучается на тесте).
3.  Метрика ROC-AUC на тестовых данных должна быть адекватной (выше 0.7).

